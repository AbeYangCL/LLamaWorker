{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",
  // LLM 服务配置
  "LLmModelSettings": [
    {
      "Name": "Phi-3-mini-4k-instruct-q4",
      "Description": "The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties. https://huggingface.co/microsoft/Phi-3-mini-4k-instruct",
      "Version": "1.0",
      "SystemPrompt": "You are a helpful AI assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\Phi-3-mini-4k-instruct-gguf\\Phi-3-mini-4k-instruct-q4.gguf",
        "ContextSize": 4096,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<|user|>", "<|end|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.ZephyrHistoryTransform",
        "OutputTransform": "LLamaWorker.Transform.ZephyrTextStreamTransform"
      }
    },
    {
      "Name": "codegemma:7b-instruct_q4",
      "Description": "CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following. https://ollama.com/library/codegemma:7b",
      "Version": "1.0",
      "SystemPrompt": "You are a helpful, respectful and honest coding assistant.\nAlways reply with using markdown.\nFor code refactoring, use markdown with code formatting.\n  ",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\google\\codegemma.gguf",
        "ContextSize": 4096,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<start_of_turn>", "<end_of_turn>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.GemmaHistoryTransform",
        "OutputTransform": "LLamaWorker.Transform.GemmaTextStreamTransform"
      }
    },
    {
      "Name": "qwen7b",
      "Description": "通义千问 v1.5 7b Chat q5_k https://github.com/QwenLM/Qwen1.5",
      "Version": "1.5",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen1_5-7b-chat-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 50
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform",
        "OutputTransform": "LLamaWorker.Transform.BaseTextStreamTransform"
      }
    },
    {
      "Name": "qwen0.5b",
      "Description": "通义千问 v1.5 0.5b Chat q5_k_m https://github.com/QwenLM/Qwen1.5",
      "Version": "1.5",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\Qwen1.5-0.5B-Chat-GGUF\\qwen1_5-0_5b-chat-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform",
        "OutputTransform": "LLamaWorker.Transform.BaseTextStreamTransform"
      }
    }
  ],
  // 独立 embedding 服务配置
  "Embeding": {
    "Enabled": true,
    // 服务转发
    "Forward": false,
    "ForwardUrl": "http://127.0.0.1:5000/embeddings",
    // 本地加载
    "Path": "H:\\workspace\\gpt\\models\\mxbai-embed-large-v1\\gguf\\mxbai-embed-large-v1-f16.gguf",
    "Name": "mxbai-embed-large-v1",
    "RunType": "GPU",
    "Description": "The crispy sentence embedding family from mixedbread ai.",
    "Version": "1.0"
  }
}
