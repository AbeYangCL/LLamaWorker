{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",
  // API Key
  "ApiKey": "",
  "GlobalSettings": {
    "CurrentModelIndex": 0,
    // 自动释放时间，分钟。0 表示不自动释放
    "AutoReleaseTime": 30
  },
  // LLM 服务配置
  "LLmModelSettings": [
    {
      "Name": "qwen2_7b",
      "Description": "通义千问 v2 7b instruct q5_k_m",
      "Version": "2",
      "WebSite": "https://github.com/QwenLM/Qwen2",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen2-7b-instruct-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 50,
        "FlashAttention": true
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      },
      "ToolPrompt": {
        "Index": 0, // 工具提示配置索引
        "Lang": "zh" //工具提示词语言
      }
    },
    {
      "Name": "gemma2",
      "Description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
      "Version": "2.0",
      "WebSite": "https://huggingface.co/google/gemma-2-9b",
      "SystemPrompt": "You are a helpful assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\gemma2-9b.gguf",
        "ContextSize": 8192,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<start_of_turn>", "<end_of_turn>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.GemmaHistoryTransform"
      }
    },
    {
      "Name": "Llama3-8B-instruct",
      "Description": "Meta Llama 3, a family of models developed by Meta Inc. are new state-of-the-art , available in both 8B and 70B parameter sizes (pre-trained or instruction-tuned).",
      "WebSite": "https://ai.meta.com/blog/meta-llama-3/",
      "Version": "1.0",
      "SystemPrompt": "You are a helpful assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\llama3.gguf",
        "ContextSize": 8192,
        "Seed": 1337,
        "GpuLayerCount": 20,
        "Embeddings": false
      },
      "AntiPrompts": [ "<|eot_id|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.LLamaHistoryTransform"
      }
    },
    {
      "Name": "Llama3-8B-Chinese-Instruct",
      "Description": "This is the first model specifically fine-tuned for Chinese & English user through ORPO [1] based on the Meta-Llama-3-8B-Instruct model.",
      "WebSite": "https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3-gguf",
      "Version": "3",
      "SystemPrompt": "You are a helpful assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\llama-3-chinese-8b-instruct-v3-q5_k.gguf",
        "ContextSize": 8192,
        "Seed": 1337,
        "GpuLayerCount": 20,
        "Embeddings": false
      },
      "AntiPrompts": [ "<|eot_id|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.LLamaHistoryTransform"
      }
    },
    {
      "Name": "Phi-3-mini-4k-instruct-q4",
      "Description": "The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties.",
      "WebSite": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct",
      "Version": "1.0",
      "SystemPrompt": "You are a helpful AI assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\Phi-3-mini-4k-instruct-gguf\\Phi-3-mini-4k-instruct-q4.gguf",
        "ContextSize": 4096,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<|user|>", "<|end|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.ZephyrHistoryTransform"
      }
    },
    {
      "Name": "codegemma:7b-instruct_q4",
      "Description": "CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.",
      "Version": "1.0",
      "WebSite": "https://ollama.com/library/codegemma:7b",
      "SystemPrompt": "You are a helpful, respectful and honest coding assistant.\nAlways reply with using markdown.\nFor code refactoring, use markdown with code formatting.\n  ",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\google\\codegemma.gguf",
        "ContextSize": 4096,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<start_of_turn>", "<end_of_turn>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.GemmaHistoryTransform"
      }
    },
    {
      "Name": "qwen7b",
      "Description": "通义千问 v1.5 7b Chat q5_k",
      "Version": "1.5",
      "WebSite": "https://github.com/QwenLM/Qwen1.5",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen1_5-7b-chat-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 50
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      }
    },
    {
      "Name": "qwen0.5b",
      "Description": "通义千问 v1.5 0.5b Chat q5_k_m",
      "Version": "1.5",
      "WebSite": "https://github.com/QwenLM/Qwen1.5",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\Qwen1.5-0.5B-Chat-GGUF\\qwen1_5-0_5b-chat-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      }
    }
  ],
  "ToolPromptConfig": [
    {
      "PromptConfigDesc": "千问模板",
      "FN_NAME": "✿FUNCTION✿", // 函数名标识
      "FN_ARGS": "✿ARGS✿", // 参数标识
      "FN_RESULT": "✿RESULT✿", // 结果标识
      "FN_EXIT": "✿RETURN✿", // 工具执行后推理标识
      "FN_STOP_WORDS": [ "✿RESULT✿", "✿RETURN✿" ], // 使用工具时的特殊停止词
      "FN_TEST": "✿FUNCTION✿:? ?(.*?)\\s*(✿ARGS✿:? ?(.*?)\\s*)(?=✿RESULT✿|$|\\n)", // 函数调提取的正则表达式，用于提取函数名和参数
      "FN_RESULT_TEMPLATE": "{0}: {1}", // 结果填充模板
      "FN_CALL_TEMPLATE_INFO": {
        "zh": "# 工具\n\n## 你拥有如下工具：\n\n{tool_descs}",
        "en": "# Tools\n\n## You have access to the following tools:\n\n{tool_descs}"
      },
      "FN_CALL_TEMPLATE_FMT": {
        "zh": "## 你可以在回复中插入零次、一次或多次以下命令以调用工具：\n\n{0}: 工具名称，必须是[{4}]之一。\n{1}: 工具输入\n{2}: 工具结果\n{3}: 根据工具结果进行回复，需将图片用![](url)渲染出来",
        "en": "## When you need to call a tool, please insert the following command in your reply, which can be called zero or multiple times according to your needs:\n\n{0}: The tool to use, should be one of [{4}]\n{1}: The input of the tool\n{2}: Tool results\n{3}: Reply based on tool results. Images need to be rendered as ![](url)"
      },
      "FN_CALL_TEMPLATE_FMT_PARA": {
        "zh": "## 你可以在回复中插入以下命令以并行调用N个工具：\n\n{0}: 工具1的名称，必须是[{4}]之一\n{1}: 工具1的输入\n{0}: 工具2的名称\n{1}: 工具2的输入\n...\n{0}: 工具N的名称\n{1}: 工具N的输入\n{2}: 工具1的结果\n{2}: 工具2的结果\n...\n{2}: 工具N的结果\n{3}: 根据工具结果进行回复，需将图片用![](url)渲染出来",
        "en": "## Insert the following command in your reply when you need to call N tools in parallel:\n\n{0}: The name of tool 1, should be one of [{4}]\n{1}: The input of tool 1\n{0}: The name of tool 2\n{1}: The input of tool 2\n...\n{0}: The name of tool N\n{1}: The input of tool N\n{2}: The result of tool 1\n{2}: The result of tool 2\n...\n{2}: The result of tool N\n{3}: Reply based on tool results. Images need to be rendered as ![](url)"
      },
      "ToolDescTemplate": {
        "zh": "### {0}\n\n{1}: {2} 输入参数：[{3}]",
        "en": "### {0}\n\n{1}: {2} Parameters: [{3}]"
      }
    }
  ],
  // 独立 embedding 服务配置
  "EmbedingForward": "http://127.0.0.1:5000/embeddings"
}
